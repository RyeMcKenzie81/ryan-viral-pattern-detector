# Phase 8: Full Autonomous Intelligence ‚Äî Implementation Plan

**Branch**: `feat/ad-creator-v2-phase0`
**Created**: 2026-02-16
**Status**: 8A COMPLETE ‚Äî 8B PLANNING
**Parent Plan**: `docs/plans/ad-creator-v2/PLAN.md` Sections 10, 13, 14, Phase 8 checklist

> **Sub-phasing**: Phase 8 splits into 8A (Core Intelligence) and 8B (Advanced Intelligence), each with separate checkpoints and gates. 8A ships first; 8B follows. The original Phase 8 success gate applies to the combined 8A+8B completion.

---

## Phase 1: INTAKE

### 1.1 Original Request

Build Phase 8 ("Full Autonomous Intelligence") from the Ad Creator V2 plan. Phase 6 (Creative Genome) and Phase 7 (Winner Evolution + Experiments) provide the learning foundation. Phase 8 makes the system self-improving.

### 1.2 Scope Decision

**8A ‚Äî Core Intelligence** (this plan, ships first):
1. **Few-Shot Exemplar Library** ‚Äî Curate 20-30 calibration ads per brand, inject 3-5 most similar exemplars via embedding similarity into review prompts
2. **Adaptive Threshold Calibration** ‚Äî Weekly cron job that auto-proposes new `quality_scoring_config` based on false positive/negative rates (operator approval in Settings before activation)
3. **Visual Embedding Space** ‚Äî Gemini Flash extracts structured visual descriptors ‚Üí OpenAI text-embedding-3-small ‚Üí pgvector for exemplar similarity + "more like this" (Winner Evolution)
   - **Model note**: Parent plan (Section 14) specifies "Gemini 3 Flash" ‚Äî not yet available. 8A uses `gemini-2.0-flash`; upgrade when 3.0 ships. The `extraction_model` column on `visual_embeddings` tracks which model was used, enabling re-extraction after upgrade.
4. **Interaction Effect Detection** ‚Äî Detect top 15 element pair interactions from `creative_element_rewards` joined with `generated_ads.element_tags`, surface in Genome advisory + Settings read-only view
5. **FatigueScorer** ‚Äî Hybrid predictive fatigue: template-level decay + element-combo modifier, replaces reactive fatigue detection in Phase 7A's anti-fatigue refresh

**8B ‚Äî Advanced Intelligence** (separate plan, after 8A ships):
- Genome-learned scorer weights (Thompson Sampling updates all scorer weights, not just PerformanceScorer)
- Prompt/pipeline A/B testing (`generation_experiments` table)
- Cross-brand transfer learning (opt-in)
- Competitive whitespace identification
- Full scorer weight transition

### 1.3 Clarifying Questions ‚Äî Answered

| # | Question | Answer |
|---|----------|--------|
| 1 | Scope split? | 8A/8B. 8A = core 5 features (exemplar, calibration, visual embedding, interactions, fatigue). 8B = remaining 5. |
| 2 | Exemplar curation? | Auto-seed from override history + manual "Mark as Exemplar" override. Per-brand caps: ~10 gold_approve, ~10 gold_reject, ~5-10 edge_case. Diversity constraints (template/canvas/color/persona). Provenance tracked. |
| 3 | Calibration approval? | Settings page review. Weekly job proposes ‚Üí operator Activates or Dismisses. Full audit trail. Safety rails: min sample size, bounded delta limits. |
| 4 | Visual embedding primary use? | Exemplar similarity for few-shot review. Secondary: "more like this" for Winner Evolution. Defer duplicate detection, clustering, diversity to 8B. |
| 5 | Interaction storage? | `element_interactions` table + Genome advisory context + Settings read-only view. No direct prompt injection in 8A. |
| 6 | FatigueScorer input? | Hybrid: template-level base decay (days since template_id last used for product+audience) + element-combo modifier (hook_type √ó color_mode √ó template_category). Combo modifier neutral when data sparse. Score bounded [0.2, 1.0]. |
| 7 | Embedding method? | Text descriptors only for 8A. Gemini Flash extracts descriptors ‚Üí embed with text-embedding-3-small. Schema fields for future hybrid upgrade. Defer image embeddings to 8B. |

### 1.4 Success Criteria (8A Gate)

- [ ] Exemplar library populated for >= 1 brand (auto-seed + manual curation UI functional)
- [ ] Exemplars injected into review prompts (3-5 most similar via embedding similarity)
- [ ] At least one calibration proposal generated by weekly job with correct metrics
- [ ] Operator can Activate/Dismiss proposals in Settings page
- [ ] Visual embeddings generated for >= 50 ads (Gemini Flash extraction + OpenAI embedding)
- [ ] Exemplar similarity search returns relevant matches (manual spot-check)
- [ ] Top 15 interaction effects detected and displayed in Settings
- [ ] FatigueScorer active in template scoring pipeline with hybrid decay
- [ ] `element_combo_usage` table tracking combo usage for predictive curves
- [ ] All `python3 -m py_compile` pass on changed files
- [ ] Post-phase review PASS

### 1.5 Final Success Gate (8A + 8B combined, from parent plan)

- [ ] Human override rate decreasing quarter-over-quarter (>= 50 overrides per quarter)
- [ ] Approval rate trend positive over 8-week rolling window
- [ ] At least one autonomous threshold adjustment accepted by operator

---

## Phase 2: ARCHITECTURE DECISION

### 2.1 Workflow Type per Feature

| Feature | Pattern | Reasoning |
|---------|---------|-----------|
| Exemplar Library | Service + DB + UI | Manual curation (operator-driven), auto-seed is a one-time batch |
| Adaptive Calibration | Service + Weekly Cron Job | Deterministic analysis ‚Üí propose ‚Üí human approve. No AI branching. |
| Visual Embedding Space | Service + DB (pgvector) | Extraction + storage are batch operations. Retrieval is query-time. |
| Interaction Detection | Service + Weekly Job (piggybacked on `genome_validation`) | Statistical computation over existing data. No AI decisions. |
| FatigueScorer | Scorer class (stateless) + usage tracking table | Follows existing `TemplateScorer` ABC. Reads from DB, returns score. |

**No pydantic-graph needed** ‚Äî all features are either batch jobs, UI-driven services, or stateless scorers.

### 2.2 High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Weekly Cron Jobs                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  quality_calibration job ‚îÄ‚îÄ‚ñ∫ QualityCalibrationService          ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ Analyze override rates (false pos/neg)                ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ Propose new quality_scoring_config                    ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ Store as inactive, pending operator approval          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  genome_validation job ‚îÄ‚îÄ‚ñ∫ InteractionDetectorService           ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ Compute pairwise element effect sizes                 ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ Store top 15 in element_interactions                  ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ Update Genome advisory context                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Visual Embedding Pipeline                     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  On ad generation complete:                                     ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ Gemini Flash extracts structured descriptors          ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ OpenAI text-embedding-3-small embeds descriptor text  ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ Store in visual_embeddings (pgvector VECTOR(1536))    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  On review (exemplar injection):                                ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ Retrieve ad's visual embedding                        ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ pgvector similarity search ‚Üí top 5 exemplars          ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ Inject into review prompt as few-shot examples        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Template Scoring Pipeline                     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Existing: AssetMatch, UnusedBonus, CategoryMatch,              ‚îÇ
‚îÇ            AwarenessAlign, AudienceMatch, BeliefClarity,        ‚îÇ
‚îÇ            Performance                                          ‚îÇ
‚îÇ  NEW:      FatigueScorer (hybrid template + element combo)      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Weight presets updated:                                         ‚îÇ
‚îÇ    SMART_SELECT_WEIGHTS["fatigue"] = 0.4                        ‚îÇ
‚îÇ    ROLL_THE_DICE_WEIGHTS["fatigue"] = 0.2                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         UI Changes                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Results Dashboard:                                             ‚îÇ
‚îÇ    + "Mark as Exemplar" button (gold_approve/gold_reject/edge)  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Settings Page:                                                 ‚îÇ
‚îÇ    + Calibration Proposals tab (view/activate/dismiss)          ‚îÇ
‚îÇ    + Interaction Effects tab (read-only knowledge base)         ‚îÇ
‚îÇ    + Exemplar Library tab (view/manage exemplars per brand)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Phase 3: INVENTORY & GAP ANALYSIS

### 3.1 Existing Components to Reuse

| Component | Location | How Used in 8A |
|-----------|----------|----------------|
| `CreativeGenomeService` | `services/creative_genome_service.py` | Element scores for interaction detection; advisory context enhanced with interactions |
| `AdReviewService` | `pipelines/ad_creation_v2/services/review_service.py` | Inject exemplars into review prompts |
| `TemplateScoringService` | `services/template_scoring_service.py` | Add FatigueScorer to scorer list |
| `quality_scoring_config` table | Migration `2026-02-14_phase4.sql` | Adaptive calibration creates new versions |
| `ad_review_overrides` table | Migration `2026-02-14_phase4.sql` | Auto-seed exemplars from override history |
| `creative_element_scores` table | Migration `2026-02-15_creative_genome.sql` | Interaction detection reads pairwise stats |
| `generated_ads` table | Existing | Exemplar source; visual embedding link |
| `WinnerEvolutionService` | `services/winner_evolution_service.py` | "More like this" visual similarity for evolution |
| Scheduler Worker | `worker/scheduler_worker.py` | Route `quality_calibration` job |

### 3.2 New Tables

| Table | Purpose | Collision Check |
|-------|---------|----------------|
| `exemplar_library` | Curated calibration ads per brand | No collision (searched codebase) |
| `visual_embeddings` | Structured descriptors + pgvector embeddings | No collision |
| `element_interactions` | Detected pairwise element synergies/conflicts | No collision |
| `element_combo_usage` | Track element combo usage for fatigue curves | No collision |
| `calibration_proposals` | Proposed quality_scoring_config changes pending approval | No collision |

### 3.3 New Columns on Existing Tables

| Column | Table | Purpose |
|--------|-------|---------|
| None needed | ‚Äî | All new data goes in dedicated tables |

### 3.4 New Job Types

| Job Type | Frequency | Handler |
|----------|-----------|---------|
| `quality_calibration` | Weekly | `execute_quality_calibration_job()` |

Note: `quality_calibration` is already in the `scheduled_jobs.job_type` CHECK constraint (added in Phase 0 migration). Interaction detection piggybacks on existing `genome_validation` job.

### 3.4b Ops Bootstrap: Recurring Job Setup

The `quality_calibration` worker handler will exist after P8A-C6, but **a recurring `scheduled_jobs` row must be created** for it to actually run. This is handled in P8A-C6 as part of the worker chunk:

**Option A (migration seed)**: Add to the Phase 8A migration:
```sql
-- Seed weekly quality_calibration job (runs every Sunday at 03:00 PST)
-- IMPORTANT: scheduler_worker.py cron parser uses Python weekday() (Mon=0..Sun=6),
-- NOT standard cron (Sun=0). So day_of_week=6 means Sunday.
-- All cron times are PST (calculate_next_run uses datetime.now(PST)).
-- Global job (no brand/product). Operator can adjust frequency in Scheduler UI.
INSERT INTO scheduled_jobs (
    job_type, name, schedule_type, cron_expression,
    next_run_at, status, parameters
)
SELECT 'quality_calibration', 'Weekly Quality Calibration', 'recurring',
       '0 3 * * 6',               -- 6 = Sunday in Python weekday() (Mon=0..Sun=6)
       NOW() + interval '5 minutes',  -- first run near-immediate to verify handler works
       'active', '{"window_days": 30}'::jsonb
WHERE NOT EXISTS (
    SELECT 1 FROM scheduled_jobs WHERE job_type = 'quality_calibration'
);
```
Uses `WHERE NOT EXISTS` for idempotent seeding (no unique constraint on `job_type`). Day-of-week `6` = Sunday per Python `weekday()` convention used by the worker's cron parser (`scheduler_worker.py:515`).

**Option B (manual setup)**: Document in P8A-C7 UI chunk that the Settings > Calibration tab includes a "Set Up Recurring Calibration" button that creates the job if none exists.

**Chosen**: Option A (migration seed) for the global job. Per-org jobs can be created via UI later. This ensures the handler is exercised immediately after deployment.

### 3.5 New Components to Build

| # | Component | Type | Location | Purpose |
|---|-----------|------|----------|---------|
| 1 | Migration: Phase 8A tables | SQL | `migrations/2026-02-16_ad_creator_v2_phase8a.sql` | 5 new tables |
| 2 | `ExemplarService` | Service | `pipelines/ad_creation_v2/services/exemplar_service.py` | CRUD, auto-seed, similarity search, prompt injection |
| 3 | `VisualDescriptorService` | Service | `pipelines/ad_creation_v2/services/visual_descriptor_service.py` | Gemini extraction, OpenAI embedding, pgvector queries |
| 4 | `QualityCalibrationService` | Service | `services/quality_calibration_service.py` | Analyze overrides, propose thresholds, activation logic |
| 5 | `InteractionDetectorService` | Service | `services/interaction_detector_service.py` | Pairwise effect detection, top-15 ranking |
| 6 | `FatigueScorer` | Scorer | `services/template_scoring_service.py` | Template-level + element-combo hybrid fatigue |
| 7 | Worker handler | Worker | `worker/scheduler_worker.py` | `execute_quality_calibration_job()` |
| 8 | Worker enhancement | Worker | `worker/scheduler_worker.py` | Add interaction detection to `execute_genome_validation_job()` |
| 9 | Review service enhancement | Service | `pipelines/ad_creation_v2/services/review_service.py` | Inject exemplars into `_build_rubric_prompt()` for Stage 2/3 review |
| 10 | UI: Exemplar management | UI | `ui/pages/21b_üé®_Ad_Creator_V2.py` | "Mark as Exemplar" button in results dashboard |
| 11 | UI: Settings enhancements | UI | `ui/pages/64_‚öôÔ∏è_Platform_Settings.py` | Calibration Proposals, Interaction Effects, Exemplar Library tabs |
| 12 | Unit tests | Tests | `tests/services/test_exemplar_service.py`, `test_visual_descriptor_service.py`, `test_quality_calibration_service.py`, `test_interaction_detector_service.py`, `test_fatigue_scorer.py` | Tests for all new services |

### 3.6 Detailed Table Designs

#### `exemplar_library`

```sql
CREATE TABLE IF NOT EXISTS exemplar_library (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    brand_id UUID NOT NULL REFERENCES brands(id) ON DELETE CASCADE,
    generated_ad_id UUID NOT NULL REFERENCES generated_ads(id) ON DELETE CASCADE,

    -- Classification
    category TEXT NOT NULL,  -- gold_approve, gold_reject, edge_case

    -- Provenance
    source TEXT NOT NULL DEFAULT 'manual',  -- auto, manual
    source_reason TEXT,                      -- e.g., "override_approved", "high_confidence_reject"
    created_by UUID,                         -- user who marked it (NULL for auto-seed)

    -- Diversity attributes (for balanced curation)
    template_category TEXT,     -- from generated_ads.element_tags
    canvas_size TEXT,           -- from generated_ads.canvas_size
    color_mode TEXT,            -- from generated_ads.color_mode
    persona_id UUID,            -- from generated_ads.element_tags.persona_id

    -- Embedding link
    visual_embedding_id UUID,   -- FK to visual_embeddings (populated after embedding)

    -- Status
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    deactivated_at TIMESTAMPTZ,
    deactivated_reason TEXT,

    created_at TIMESTAMPTZ DEFAULT NOW(),

    UNIQUE(brand_id, generated_ad_id)
);

-- CHECK constraint on category
ALTER TABLE exemplar_library
ADD CONSTRAINT exemplar_library_category_check
CHECK (category IN ('gold_approve', 'gold_reject', 'edge_case'));

ALTER TABLE exemplar_library
ADD CONSTRAINT exemplar_library_source_check
CHECK (source IN ('auto', 'manual'));
```

#### `visual_embeddings`

```sql
-- Requires pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE IF NOT EXISTS visual_embeddings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    generated_ad_id UUID NOT NULL REFERENCES generated_ads(id) ON DELETE CASCADE,
    brand_id UUID NOT NULL,

    -- Structured descriptors (from Gemini Flash)
    visual_descriptors JSONB NOT NULL,
    -- Schema: {
    --   "layout_type": "grid|hero|split|minimal|overlay",
    --   "color_palette": ["#hex1", "#hex2", ...],
    --   "dominant_colors": ["warm_red", "cool_blue", ...],
    --   "visual_style": "ugc|studio|lifestyle|minimal|graphic",
    --   "composition": "centered|rule_of_thirds|asymmetric|full_bleed",
    --   "text_placement": "top|bottom|center|overlay|sidebar",
    --   "text_density": "minimal|moderate|heavy",
    --   "has_person": bool,
    --   "has_product": bool,
    --   "mood": "energetic|calm|urgent|professional|playful",
    --   "background_type": "solid|gradient|photo|pattern"
    -- }

    -- Embedding (OpenAI text-embedding-3-small, 1536 dims)
    embedding VECTOR(1536),

    -- Versioning for future upgrades
    descriptor_schema_version TEXT NOT NULL DEFAULT 'v1',
    descriptor_embedding_version TEXT NOT NULL DEFAULT 'text-embedding-3-small-v1',
    extraction_model TEXT NOT NULL DEFAULT 'gemini-2.0-flash',  -- Parent plan (Section 14) says "Gemini 3 Flash" ‚Äî not yet available; use gemini-2.0-flash for 8A, upgrade when 3.0 ships

    created_at TIMESTAMPTZ DEFAULT NOW(),

    UNIQUE(generated_ad_id)
);

-- pgvector index for similarity search
CREATE INDEX IF NOT EXISTS idx_visual_embeddings_vector
  ON visual_embeddings USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

CREATE INDEX IF NOT EXISTS idx_visual_embeddings_brand
  ON visual_embeddings(brand_id);
```

#### `element_interactions`

```sql
CREATE TABLE IF NOT EXISTS element_interactions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    brand_id UUID NOT NULL REFERENCES brands(id) ON DELETE CASCADE,

    -- Element pair
    element_a_name TEXT NOT NULL,    -- e.g., "hook_type"
    element_a_value TEXT NOT NULL,   -- e.g., "curiosity_gap"
    element_b_name TEXT NOT NULL,    -- e.g., "color_mode"
    element_b_value TEXT NOT NULL,   -- e.g., "warm"

    -- Effect metrics
    interaction_effect FLOAT NOT NULL,       -- lift/drag vs independent expectation (e.g., +0.15 = 15% lift)
    effect_direction TEXT NOT NULL,           -- synergy, conflict, neutral
    confidence_interval_low FLOAT,
    confidence_interval_high FLOAT,
    sample_size INT NOT NULL,                -- number of ads with this combo
    p_value FLOAT,                           -- statistical significance

    -- Ranking
    effect_rank INT,                          -- 1-15 within brand (top 15)

    -- Metadata
    computed_at TIMESTAMPTZ DEFAULT NOW(),
    computation_window_days INT DEFAULT 90,   -- how far back data was analyzed

    -- Canonical ordering: element_a < element_b (alphabetically by name, then value)
    -- Enforced by service before upsert to prevent storing both (A,B) and (B,A)
    UNIQUE(brand_id, element_a_name, element_a_value, element_b_name, element_b_value)
);

ALTER TABLE element_interactions
ADD CONSTRAINT element_interactions_direction_check
CHECK (effect_direction IN ('synergy', 'conflict', 'neutral'));

-- Note: canonical ordering enforced at service layer:
--   if (a_name, a_value) > (b_name, b_value): swap(a, b)
-- This ensures each pair is stored exactly once per brand.
```

#### `element_combo_usage`

```sql
CREATE TABLE IF NOT EXISTS element_combo_usage (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    brand_id UUID NOT NULL,
    product_id UUID,                 -- NULL = brand-wide

    -- Combo key (sorted canonical form: "color_mode=brand|hook_type=curiosity_gap|template_category=testimonial")
    combo_key TEXT NOT NULL,

    -- Individual elements (for querying)
    hook_type TEXT,
    color_mode TEXT,
    template_category TEXT,
    awareness_stage TEXT,

    -- Usage tracking
    last_used_at TIMESTAMPTZ NOT NULL,
    times_used INT NOT NULL DEFAULT 1,

    -- Performance at last use (for decay weighting)
    last_reward_score FLOAT,

    -- Idempotency guard: last ad_run_id that updated this row
    -- Only increment times_used when last_ad_run_id != current run
    last_ad_run_id UUID,

    -- No table-level UNIQUE with COALESCE; use CREATE UNIQUE INDEX instead
    -- (Postgres requires functional expressions in index, not table constraint)
);

-- Expression must exactly match ON CONFLICT target (same COALESCE + uuid cast)
CREATE UNIQUE INDEX IF NOT EXISTS idx_ecu_unique_combo
  ON element_combo_usage(brand_id, COALESCE(product_id, '00000000-0000-0000-0000-000000000000'::uuid), combo_key);

CREATE INDEX IF NOT EXISTS idx_ecu_brand_product
  ON element_combo_usage(brand_id, product_id);
CREATE INDEX IF NOT EXISTS idx_ecu_last_used
  ON element_combo_usage(last_used_at);
```

#### `calibration_proposals`

```sql
CREATE TABLE IF NOT EXISTS calibration_proposals (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID,              -- NULL = global

    -- Current vs proposed config
    current_config_id UUID REFERENCES quality_scoring_config(id),
    proposed_pass_threshold NUMERIC(4,2) NOT NULL,
    proposed_check_weights JSONB NOT NULL,
    proposed_borderline_range JSONB NOT NULL,
    proposed_auto_reject_checks JSONB NOT NULL,

    -- Analysis metrics
    analysis_window_start DATE NOT NULL,
    analysis_window_end DATE NOT NULL,
    total_overrides_analyzed INT NOT NULL,
    false_positive_rate FLOAT,          -- AI approved, human rejected (override_reject / total_approved)
    false_negative_rate FLOAT,          -- AI rejected, human approved (override_approve / total_rejected)
    expected_approval_rate_change FLOAT, -- estimated delta in approval rate

    -- Safety checks
    meets_min_sample_size BOOLEAN NOT NULL DEFAULT FALSE,
    within_delta_bounds BOOLEAN NOT NULL DEFAULT FALSE,
    min_sample_size_required INT NOT NULL DEFAULT 30,
    max_threshold_delta NUMERIC(4,2) NOT NULL DEFAULT 1.00,  -- max change from current

    -- Status
    status TEXT NOT NULL DEFAULT 'proposed',  -- proposed, activated, dismissed, insufficient_evidence
    proposed_by_job_id UUID,                  -- scheduled_job_runs.id
    proposed_at TIMESTAMPTZ DEFAULT NOW(),
    activated_by UUID,                        -- user who activated
    activated_at TIMESTAMPTZ,
    activated_config_id UUID,                 -- quality_scoring_config.id created on activation
    dismissed_by UUID,
    dismissed_at TIMESTAMPTZ,
    dismissed_reason TEXT,

    notes TEXT
);

ALTER TABLE calibration_proposals
ADD CONSTRAINT calibration_proposals_status_check
CHECK (status IN ('proposed', 'activated', 'dismissed', 'insufficient_evidence'));
```

### 3.7 Service API Designs

#### ExemplarService

```python
class ExemplarService:
    """Few-shot exemplar library for review calibration."""

    # --- Auto-seeding ---
    async def auto_seed_exemplars(self, brand_id: UUID) -> Dict:
        """Auto-seed exemplars from override history.
        Target: ~10 gold_approve, ~10 gold_reject, ~5-10 edge_case.
        Enforces diversity (template_category, canvas_size, color_mode, persona).

        IMPORTANT: Filters to latest override per ad only (superseded_by IS NULL)
        to avoid seeding from stale/outdated override labels. The ad_review_overrides
        table allows multiple overrides per ad; only the final decision matters.

        Classification rules:
        - override_approve + superseded_by IS NULL ‚Üí gold_approve candidate
        - override_reject + superseded_by IS NULL ‚Üí gold_reject candidate
        - confirm + borderline weighted_score (5.0-7.0) + superseded_by IS NULL ‚Üí edge_case candidate

        Returns: {seeded: int, gold_approve: int, gold_reject: int, edge_case: int}
        """

    # --- CRUD ---
    async def mark_as_exemplar(
        self, brand_id: UUID, generated_ad_id: UUID, category: str,
        created_by: Optional[UUID] = None
    ) -> Dict:
        """Mark a generated ad as an exemplar. Enforces per-brand cap (30)."""

    async def remove_exemplar(self, exemplar_id: UUID, reason: str) -> None:
        """Deactivate an exemplar (soft delete)."""

    async def get_exemplars(
        self, brand_id: UUID, category: Optional[str] = None
    ) -> List[Dict]:
        """List active exemplars for a brand."""

    async def get_exemplar_stats(self, brand_id: UUID) -> Dict:
        """Get counts by category and diversity metrics."""

    # --- Similarity Search ---
    async def find_similar_exemplars(
        self, brand_id: UUID, ad_embedding: List[float],
        category: Optional[str] = None, limit: int = 5
    ) -> List[Dict]:
        """Find most similar exemplars via pgvector cosine similarity."""

    # --- Review Prompt Injection ---
    async def build_exemplar_context(
        self, brand_id: UUID, ad_embedding: List[float]
    ) -> str:
        """Build few-shot exemplar context for review prompts.
        Returns formatted text with 3-5 exemplars (balanced: approve + reject + edge).
        """
```

#### VisualDescriptorService

```python
class VisualDescriptorService:
    """Visual embedding extraction and similarity search."""

    # --- Extraction ---
    async def extract_descriptors(
        self, image_data: bytes, media_type: str = "image/png"
    ) -> Dict:
        """Extract structured visual descriptors using Gemini Flash.
        Returns: {layout_type, color_palette, visual_style, composition, ...}
        """

    async def embed_descriptors(self, descriptors: Dict) -> List[float]:
        """Embed descriptor text using OpenAI text-embedding-3-small.
        Returns: 1536-dim embedding vector.
        """

    async def extract_and_store(
        self, generated_ad_id: UUID, brand_id: UUID,
        image_data: bytes, media_type: str = "image/png"
    ) -> UUID:
        """Full pipeline: extract ‚Üí embed ‚Üí store. Returns visual_embeddings.id."""

    # --- Similarity Search ---
    async def find_similar_ads(
        self, brand_id: UUID, embedding: List[float], limit: int = 10,
        exclude_ad_id: Optional[UUID] = None
    ) -> List[Dict]:
        """Find similar ads via pgvector cosine similarity."""

    async def get_embedding(self, generated_ad_id: UUID) -> Optional[List[float]]:
        """Get stored embedding for an ad."""
```

#### QualityCalibrationService

```python
class QualityCalibrationService:
    """Adaptive threshold calibration from human override data."""

    async def analyze_overrides(
        self, organization_id: Optional[UUID] = None,
        window_days: int = 30
    ) -> Dict:
        """Analyze override patterns for false positive/negative rates.
        Returns: {total_overrides, false_positive_rate, false_negative_rate,
                  per_check_rates: {V1: {fp: .., fn: ..}, ...}}
        """

    async def propose_calibration(
        self, organization_id: Optional[UUID] = None,
        window_days: int = 30
    ) -> Dict:
        """Generate a calibration proposal based on override analysis.

        Safety rails:
        - Min 30 overrides in analysis window (else status="insufficient_evidence")
        - Max ¬±1.0 change from current pass_threshold
        - Per-check weight changes bounded ¬±0.5 per check per proposal

        Validation (applied to proposed config before storing):
        - All 15 rubric check keys (V1-V9, C1-C4, G1-G2) must be present in check_weights
        - All weights must be non-negative (>= 0)
        - borderline_range.low must be < borderline_range.high
        - borderline_range values must be in [0, 10]
        - auto_reject_checks must be a subset of valid check IDs (V1-V9, C1-C4, G1-G2)
        - pass_threshold must be in [1.0, 10.0]

        If any validation fails ‚Üí log error + still persist a calibration_proposals row
        with status="insufficient_evidence" (for auditability), but do NOT write to
        quality_scoring_config. The proposal row records what was attempted and why it failed.

        Returns: {proposal_id, current_config, proposed_config, metrics,
                  status: "proposed"|"insufficient_evidence"}
        """

    async def activate_proposal(
        self, proposal_id: UUID, activated_by: UUID
    ) -> Dict:
        """Activate a calibration proposal. Creates new quality_scoring_config version.
        Deactivates current config, activates new one."""

    async def dismiss_proposal(
        self, proposal_id: UUID, dismissed_by: UUID, reason: str
    ) -> None:
        """Dismiss a calibration proposal with reason."""

    async def get_pending_proposals(
        self, organization_id: Optional[UUID] = None
    ) -> List[Dict]:
        """Get all pending (proposed) calibration proposals."""

    async def get_proposal_history(
        self, organization_id: Optional[UUID] = None
    ) -> List[Dict]:
        """Get full history of calibration proposals."""
```

#### InteractionDetectorService

```python
class InteractionDetectorService:
    """Detect element pair interaction effects from creative performance data."""

    async def detect_interactions(
        self, brand_id: UUID, window_days: int = 90,
        min_sample_size: int = 10
    ) -> Dict:
        """Detect top 15 element pair interactions.

        Data source: creative_element_rewards JOIN generated_ads.element_tags
        (NOT creative_element_scores ‚Äî we need per-ad reward + tag pairs, not
        pre-aggregated Beta distributions).

        Method:
        1. Load matured ads with reward_score + element_tags for this brand
        2. For each pair of TRACKED_ELEMENTS values, compute observed vs expected reward
        3. **Canonical ordering**: before computing, ensure (a_name, a_value) <= (b_name, b_value)
           alphabetically. This prevents storing both (hook_type=X, color_mode=Y) and
           (color_mode=Y, hook_type=X) as separate interactions.
        4. Expected = E[reward | A] √ó E[reward | B] / E[reward] (independence)
        5. Interaction effect = observed mean reward - expected
        6. Bootstrap 95% CI for effect estimate
        7. Rank by absolute effect size, keep top 15
        8. Classify: synergy (>0.05), conflict (<-0.05), neutral (otherwise)
        9. Upsert into element_interactions with canonical pair ordering

        Returns: {interactions: [...], total_pairs_tested, total_ads_analyzed, brand_id}
        """

    async def get_top_interactions(
        self, brand_id: UUID, limit: int = 15
    ) -> List[Dict]:
        """Get top interactions from DB (latest computation)."""

    def format_advisory_context(self, interactions: List[Dict]) -> str:
        """Format interactions for genome advisory prompt injection."""
```

#### FatigueScorer (added to template_scoring_service.py)

```python
class FatigueScorer(TemplateScorer):
    """Hybrid fatigue scorer: template decay + element combo modifier.

    Base decay: e^(-Œª * days_since_template_last_used)
    Combo modifier: adjusts decay based on element combo staleness
    Final score: clamp(base_decay * combo_modifier, 0.2, 1.0)

    Falls back to 1.0 (no fatigue) for never-used templates.
    Falls back to base_decay only when combo data is sparse.
    """
    name = "fatigue"

    DECAY_LAMBDA = 0.05  # ~14-day half-life
    COMBO_DECAY_LAMBDA = 0.03  # Slower combo decay (~23-day half-life)
    MIN_COMBO_OBSERVATIONS = 3  # Minimum uses before combo modifier applies
```

---

## Phase 4: BUILD ORDER

### 4.1 Chunk Plan

| Chunk | Scope | Est. Tokens |
|-------|-------|-------------|
| P8A-C1 | Migration: 5 new tables + job type updates | ~15K |
| P8A-C2 | `VisualDescriptorService` + `ExemplarService` (core CRUD + auto-seed) | ~40K |
| P8A-C3 | `QualityCalibrationService` + `InteractionDetectorService` | ~35K |
| P8A-C4 | `FatigueScorer` + `element_combo_usage` tracking + scoring pipeline integration | ~25K |
| P8A-C5 | Review service exemplar injection + visual embedding pipeline integration | ~30K |
| P8A-C6 | Worker handlers + genome advisory enhancement | ~20K |
| P8A-C7 | UI: "Mark as Exemplar" + Settings tabs (Calibration, Interactions, Exemplars) | ~35K |
| P8A-C8 | Unit tests for all services | ~40K |
| P8A-C9 | Post-plan review + fixes | ~15K |

### 4.2 Component Build Details

#### P8A-C1: Migration

**File**: `migrations/2026-02-16_ad_creator_v2_phase8a.sql`

Tables created:
1. `exemplar_library` ‚Äî curated calibration ads
2. `visual_embeddings` ‚Äî structured descriptors + pgvector
3. `element_interactions` ‚Äî pairwise element effects
4. `element_combo_usage` ‚Äî combo usage tracking for fatigue
5. `calibration_proposals` ‚Äî pending threshold changes

Also:
- Ensure `pgvector` extension is enabled
- Update `scheduled_jobs.job_type` CHECK if `quality_calibration` not already present

**Quality gate**: Migration applies without error, no naming collisions.

#### P8A-C2: VisualDescriptorService + ExemplarService

**Files**:
- `viraltracker/pipelines/ad_creation_v2/services/visual_descriptor_service.py`
- `viraltracker/pipelines/ad_creation_v2/services/exemplar_service.py`

VisualDescriptorService:
- `extract_descriptors()` ‚Äî Gemini Flash prompt returning structured JSON
- `embed_descriptors()` ‚Äî OpenAI text-embedding-3-small
- `extract_and_store()` ‚Äî full pipeline: extract ‚Üí embed ‚Üí insert
- `find_similar_ads()` ‚Äî pgvector cosine similarity query
- `get_embedding()` ‚Äî lookup by generated_ad_id

ExemplarService:
- `auto_seed_exemplars()` ‚Äî query `ad_review_overrides`, classify by override type, enforce diversity + per-brand cap
- `mark_as_exemplar()` / `remove_exemplar()` ‚Äî CRUD with cap enforcement
- `get_exemplars()` / `get_exemplar_stats()` ‚Äî read queries
- `find_similar_exemplars()` ‚Äî pgvector similarity restricted to exemplar_library
- `build_exemplar_context()` ‚Äî format 3-5 exemplars (balanced categories) for review prompt

**Quality gate**: Both services compile. Auto-seed populates exemplars from test data.

#### P8A-C3: QualityCalibrationService + InteractionDetectorService

**Files**:
- `viraltracker/services/quality_calibration_service.py`
- `viraltracker/services/interaction_detector_service.py`

QualityCalibrationService:
- `analyze_overrides()` ‚Äî compute false positive/negative rates from `ad_review_overrides` window
- `propose_calibration()` ‚Äî generate new threshold proposal with safety rails
  - Min sample size: 30 overrides in window
  - Max delta: ¬±1.0 from current pass_threshold
  - Per-check weight adjustment: proportional to false rate
  - If insufficient evidence ‚Üí status = 'insufficient_evidence'
- `activate_proposal()` ‚Äî create new `quality_scoring_config` version, deactivate old
- `dismiss_proposal()` ‚Äî mark dismissed with reason
- `get_pending_proposals()` / `get_proposal_history()` ‚Äî read queries

InteractionDetectorService:
- `detect_interactions()` ‚Äî pairwise analysis:
  1. Get all `creative_element_rewards` with `element_tags` for brand (window)
  2. For each pair of TRACKED_ELEMENTS, compute:
     - Observed reward when both present
     - Expected reward = E[A] √ó E[B] (marginal independence)
     - Effect = observed - expected
     - Confidence interval via bootstrap or normal approximation
  3. Rank by |effect|, keep top 15
  4. Upsert into `element_interactions`
- `get_top_interactions()` ‚Äî read top-N from table
- `format_advisory_context()` ‚Äî natural language summary for prompt

**Quality gate**: Both services compile. Calibration proposes valid config from mock data.

#### P8A-C4: FatigueScorer + Combo Usage Tracking

**Files**:
- `viraltracker/services/template_scoring_service.py` ‚Äî add `FatigueScorer` class + update scorer lists + weight presets
- `viraltracker/pipelines/ad_creation_v2/nodes/compile_results.py` ‚Äî track combo usage after generation

FatigueScorer:
- Reads `product_template_usage` for template-level last-used date
- Reads `element_combo_usage` for combo-level last-used date
- Base decay: `e^(-0.05 * days_since_template_used)` (~14-day half-life)
- Combo modifier: `e^(-0.03 * days_since_combo_used)` when observations >= 3, else 1.0
- Final score: `clamp(base_decay * combo_modifier, 0.2, 1.0)`
- Never-used templates: score = 1.0

Combo usage tracking:
- After ads are compiled in `CompileResultsNode`, record combo usage in `element_combo_usage`
- Canonical combo key: sorted "elem=val|elem=val|..." format
- **Idempotent upsert** with explicit SQL behavior:
  ```sql
  INSERT INTO element_combo_usage (brand_id, product_id, combo_key, hook_type,
    color_mode, template_category, awareness_stage, last_used_at, times_used,
    last_ad_run_id)
  VALUES (:brand_id, :product_id, :combo_key, :hook_type, :color_mode,
    :template_category, :awareness_stage, :now, 1, :ad_run_id)
  ON CONFLICT (brand_id, (COALESCE(product_id, '00000000-0000-0000-0000-000000000000'::uuid)), combo_key) DO UPDATE SET
    last_used_at = GREATEST(element_combo_usage.last_used_at, EXCLUDED.last_used_at),
    -- Only increment when incoming run differs from stored run (prevents retry double-count)
    times_used = CASE
      WHEN element_combo_usage.last_ad_run_id IS DISTINCT FROM EXCLUDED.last_ad_run_id
      THEN element_combo_usage.times_used + 1
      ELSE element_combo_usage.times_used
    END,
    last_ad_run_id = EXCLUDED.last_ad_run_id;
  ```
- **Per-ad dedup guard**: `last_ad_run_id` column tracks the last ad_run that updated this row. The `IS DISTINCT FROM` check ensures retries of the same run don't increment `times_used`. A new run with the same combo correctly increments.

Weight preset updates:
```python
ROLL_THE_DICE_WEIGHTS["fatigue"] = 0.2
SMART_SELECT_WEIGHTS["fatigue"] = 0.4
```

New scorer list:
```python
PHASE_8_SCORERS = PHASE_6_SCORERS + [FatigueScorer()]
```

**Quality gate**: FatigueScorer scores correctly for used/unused/combo scenarios. Scoring pipeline runs with 8 scorers.

#### P8A-C5: Review Prompt Exemplar Injection

**Files**:
- `viraltracker/pipelines/ad_creation_v2/services/review_service.py` ‚Äî modify `_build_rubric_prompt()` to accept optional `exemplar_context: str` parameter and inject into Stage 2 + Stage 3 prompts
- `viraltracker/pipelines/ad_creation_v2/services/review_service.py` ‚Äî modify `_run_rubric_review_claude()` and `_run_rubric_review_gemini()` to pass exemplar context through to `_build_rubric_prompt()`
- `viraltracker/pipelines/ad_creation_v2/services/review_service.py` ‚Äî modify `review_ad_staged()` to accept optional `exemplar_context: str` and pass to both Stage 2/3
- `viraltracker/pipelines/ad_creation_v2/nodes/review_ads.py` ‚Äî wire exemplar lookup before `review_service.review_ad_staged()` call

Flow:
1. In `ReviewAdsNode.run()`, before review loop, check if brand has exemplars with embeddings
2. For each ad being reviewed, get or extract its visual embedding
3. Query `ExemplarService.find_similar_exemplars()` for 3-5 matches (balanced categories)
4. Build exemplar context via `ExemplarService.build_exemplar_context()`
5. Pass `exemplar_context` to `review_service.review_ad_staged()` which flows through to `_build_rubric_prompt()`

Exemplar context format:
```
## Calibration Examples (from this brand's exemplar library)

### Example 1 [APPROVED ‚Äî Gold Standard]
- Hook: "Stop wasting money on..."
- Review scores: V1=9.0, V2=8.5, V7=9.0 (avg 8.8)
- Why approved: Strong product accuracy, clean text, professional finish

### Example 2 [REJECTED ‚Äî Known Bad]
- Hook: "You won't believe..."
- Review scores: V1=4.0, V2=3.0, V7=5.0 (avg 4.0)
- Why rejected: Garbled text, distorted product, AI artifacts

### Example 3 [EDGE CASE ‚Äî Borderline]
- Hook: "The secret ingredient..."
- Review scores: V1=7.0, V2=6.5, V7=7.0 (avg 6.8)
- Note: Passed on visual quality but borderline on text legibility
```

**Quality gate**: Review prompts include exemplar context. Exemplar injection doesn't break existing review flow.

#### P8A-C6: Worker Handlers + Genome Advisory Enhancement

**Files**:
- `viraltracker/worker/scheduler_worker.py` ‚Äî add `execute_quality_calibration_job()`
- `viraltracker/worker/scheduler_worker.py` ‚Äî enhance `execute_genome_validation_job()` with interaction detection
- `viraltracker/services/creative_genome_service.py` ‚Äî enhance `get_performance_context()` with interaction data

Worker: `execute_quality_calibration_job()`:
1. Get all orgs with override data (or global)
2. Call `QualityCalibrationService.propose_calibration()` for each
3. Log results, update job metadata

Worker: `execute_genome_validation_job()` enhancement:
1. After existing validation logic, call `InteractionDetectorService.detect_interactions()`
2. Store results

Genome advisory enhancement:
- `get_performance_context()` now includes `top_interactions` in its return dict
- Format: `"Strong synergy: curiosity_gap + warm colors (+15% lift, N=42). Avoid: authority_drop + cool colors (-12% drag, N=38)."`

**Quality gate**: Both worker handlers run without error. Advisory context includes interactions.

#### P8A-C7: UI Enhancements

**Files**:
- `viraltracker/ui/pages/21b_üé®_Ad_Creator_V2.py` ‚Äî "Mark as Exemplar" button in results dashboard section
- `viraltracker/ui/pages/64_‚öôÔ∏è_Platform_Settings.py` ‚Äî Calibration Proposals, Interaction Effects, Exemplar Library tabs

Results Dashboard (`21b_üé®_Ad_Creator_V2.py`):
- "Mark as Exemplar" dropdown on each ad card in the results view (gold_approve / gold_reject / edge_case)
- Only visible when ad has `final_status` (reviewed)
- Calls `ExemplarService.mark_as_exemplar()`
- Shows badge if ad is already an exemplar

Settings Page (`64_‚öôÔ∏è_Platform_Settings.py`, new tabs):
1. **Calibration Proposals**: List pending proposals with metrics diff, Activate/Dismiss buttons, history
2. **Interaction Effects**: Read-only table of top-15 interactions per brand, sorted by |effect|
3. **Exemplar Library**: View/manage exemplars per brand, balance indicators, auto-seed button

**Quality gate**: All UI elements render without errors. Buttons trigger correct service calls.

#### P8A-C8: Unit Tests

**Files** (concrete names ‚Äî no glob patterns):
- `tests/services/test_exemplar_service.py`
- `tests/services/test_visual_descriptor_service.py`
- `tests/services/test_quality_calibration_service.py`
- `tests/services/test_interaction_detector_service.py`
- `tests/services/test_fatigue_scorer.py`

Coverage:
- ExemplarService: auto-seed logic (override chain filtering ‚Äî superseded_by IS NULL), cap enforcement, diversity constraints, similarity search, build_exemplar_context format
- VisualDescriptorService: descriptor extraction parsing, embedding call, store/retrieve
- QualityCalibrationService: override analysis, proposal generation, safety rails (min sample, bounded delta), activation flow, dismiss flow
- InteractionDetectorService: pairwise computation from rewards+tags, ranking, effect classification, bootstrap CI, format_advisory_context
- FatigueScorer: template decay curves, combo modifier with sparse-data fallback, bounds [0.2, 1.0], edge cases (never-used, no combo data), idempotent combo upsert

**Quality gate**: All tests pass. >= 80% branch coverage for new services.

**Test execution**: `python3 -m pytest tests/services/test_exemplar_service.py tests/services/test_visual_descriptor_service.py tests/services/test_quality_calibration_service.py tests/services/test_interaction_detector_service.py tests/services/test_fatigue_scorer.py -v`

#### P8A-C9: Post-Plan Review

Run `/post-plan-review` against all changed files. Fix any issues. Produce PASS verdict.

---

## Phase 5: INTEGRATION & TEST

### 5.1 Integration Checklist

| Step | What | Verification |
|------|------|-------------|
| 1 | Run migration on Supabase | Tables created, pgvector extension active |
| 2 | `python3 -m py_compile` all new files | All pass |
| 3 | Test ExemplarService auto-seed | Populates exemplars from override data |
| 4 | Test VisualDescriptorService extraction | Gemini Flash returns valid descriptors |
| 5 | Test embedding generation + storage | pgvector stores and retrieves embeddings |
| 6 | Test exemplar similarity search | Returns relevant matches |
| 7 | Test review prompt with exemplars | Exemplar context appears in prompt |
| 8 | Test QualityCalibrationService proposal | Generates valid proposal from override data |
| 9 | Test Settings Calibration tab | Proposal displays with Activate/Dismiss |
| 10 | Test InteractionDetectorService | Detects interactions from creative_element_scores |
| 11 | Test FatigueScorer in pipeline | Template selection uses fatigue scores |
| 12 | Test combo usage tracking | element_combo_usage populated after generation |
| 13 | Test quality_calibration job | Worker runs without error |
| 14 | Full V2 pipeline e2e | Pipeline completes with Phase 8A features active |

### 5.2 Deferred UI Tests (manual browser verification)

| # | Test | Page | What to Verify |
|---|------|------|----------------|
| 1 | Mark as Exemplar button | Results Dashboard | Dropdown appears, marks ad, badge shows |
| 2 | Exemplar Library tab | Settings | Lists exemplars by brand, shows balance counts |
| 3 | Auto-Seed button | Settings / Exemplar Library | Seeds exemplars from overrides |
| 4 | Calibration Proposals tab | Settings | Shows pending proposals with metrics |
| 5 | Activate proposal | Settings / Calibration | Creates new config version, marks old inactive |
| 6 | Dismiss proposal | Settings / Calibration | Records reason, marks dismissed |
| 7 | Interaction Effects tab | Settings | Shows top-15 pairs with effect size/direction |
| 8 | Template scoring with fatigue | V2 Ad Creator | Smart Select results show fatigue scores |

---

## Questions Log

| Date | Question | Answer |
|------|----------|--------|
| 2026-02-16 | Scope split? | 8A/8B. 8A = core 5, 8B = remaining 5. |
| 2026-02-16 | Exemplar curation? | Auto-seed + manual. Per-brand caps, diversity constraints, provenance. |
| 2026-02-16 | Calibration approval? | Settings page. Operator Activates/Dismisses. Full audit trail. |
| 2026-02-16 | Visual embedding primary use? | Exemplar similarity. Defer clustering/diversity/dedup to 8B. |
| 2026-02-16 | Interactions storage? | DB table + Genome advisory. No prompt injection in 8A. |
| 2026-02-16 | FatigueScorer input? | Hybrid: template decay + combo modifier. Score [0.2, 1.0]. |
| 2026-02-16 | Embedding method? | Text descriptors only for 8A. Schema fields for future hybrid. |

---

## Risks & Mitigations

### Implementation Risks

| # | Risk | Severity | Likelihood | Mitigation |
|---|------|----------|------------|------------|
| R1 | **SQL injection in raw SQL via `exec_sql` RPC** ‚Äî `find_similar_exemplars()`, `find_similar_ads()`, and `_record_combo_usage()` use string interpolation into raw SQL queries. While `_sql_val()` escapes single quotes, the pgvector embedding string and `brand_id`/`product_id` UUID strings are also interpolated. | HIGH | LOW | All user-derived values now use `_sql_val()` escaping helper (fixed in post-plan review). UUID values come from trusted DB lookups, not user input. Consider migrating to parameterized RPC or Supabase client methods in 8B. |
| R2 | **Calibration proposal drift** ‚Äî Automated threshold proposals could gradually shift quality in an undesirable direction if override patterns are biased (e.g., operator only overrides false negatives, creating a one-sided signal). | MEDIUM | MEDIUM | Safety rails bound each change: max ¬±1.0 threshold, max ¬±0.5 weight per check per proposal. Min 30 overrides required. Operator must explicitly activate proposals. History audit trail for all proposals. |
| R3 | **Exemplar staleness** ‚Äî Exemplars curated from historical overrides may become irrelevant as brand style evolves. Old exemplars could miscalibrate review models. | MEDIUM | MEDIUM | Soft delete (`deactivated_at`) enables cleanup. Auto-seed uses `superseded_by IS NULL` for latest decision only. Per-brand caps (30 total) force periodic curation. Consider auto-rotation policy in 8B. |
| R4 | **pgvector index performance at scale** ‚Äî The ivfflat index (`lists = 100`) is tuned for moderate scale. With >100K embeddings per brand, query accuracy degrades without reindexing. | LOW | LOW | Most brands will have 100s-1000s of ads, well within ivfflat's effective range. Monitor query times. Can switch to HNSW index (exact NN) or increase `lists` if needed. `descriptor_embedding_version` column enables re-embedding after model upgrades. |
| R5 | **Gemini Flash extraction inconsistency** ‚Äî Structured descriptor extraction depends on LLM following exact JSON schema. Model updates or edge cases (blank images, screenshots, text-only ads) may produce invalid/partial descriptors. | MEDIUM | MEDIUM | `_parse_descriptors()` falls back to `_default_descriptors()` on parse failure. Partial JSON fills missing fields with `None`. Non-fatal try/except in pipeline nodes. `extraction_model` column enables model upgrade tracking. |
| R6 | **Interaction detection spurious correlations** ‚Äî With small sample sizes, pairwise effects may reflect noise rather than true synergies/conflicts. Bootstrap CIs help but don't eliminate the issue. | MEDIUM | MEDIUM | Minimum pair sample size (10 ads). Bootstrap 95% CI computed for all effects. P-value reported. Effects re-computed weekly (not accumulated). Only top 15 stored. Advisory context clearly states sample sizes. |
| R7 | **FatigueScorer cold start** ‚Äî New brands/products have empty `element_combo_usage` and sparse `product_template_usage`, making fatigue scores uniformly 1.0 (neutral). | LOW | HIGH | Intended behavior ‚Äî new brands get no fatigue penalty. Combo modifier requires `MIN_COMBO_OBSERVATIONS = 3` before activating. Score floor is 0.2 (never completely suppresses a template). System becomes useful after ~20-30 ads generated per brand. |
| R8 | **Combo tracking double-count on parallel workers** ‚Äî If multiple workers process the same ad_run concurrently (unlikely but possible with retry logic), `times_used` could increment twice. | LOW | LOW | `last_ad_run_id` dedup guard: `IS DISTINCT FROM` check prevents same-run retry from incrementing. Only a true race condition (two workers inserting for the same combo at the exact same moment) could cause a double-count. The `GREATEST(last_used_at, EXCLUDED.last_used_at)` on timestamps is also idempotent. |
| R9 | **Review prompt length with exemplars** ‚Äî Injecting 3-5 exemplar examples adds ~500-1000 tokens to the review prompt. This increases latency and cost for Stage 2/3 review calls. | LOW | HIGH | Exemplar context is optional (None when no exemplars exist). Limited to 5 exemplars max. Hook text truncated to 80 chars. Only key scores included (6 of 15 checks). Cost increase is ~5-10% per review call. |

### Operational Risks

| # | Risk | Severity | Mitigation |
|---|------|----------|------------|
| O1 | **pgvector extension not enabled** ‚Äî Migration requires `CREATE EXTENSION IF NOT EXISTS vector`. Some Supabase plans may not have pgvector available. | HIGH | Migration uses `IF NOT EXISTS`. Visual embedding features degrade gracefully (no embedding stored, exemplar similarity disabled). Verify pgvector available before applying migration. |
| O2 | **Quality calibration job runs with no override data** ‚Äî Fresh deployment has 0 overrides, producing only `insufficient_evidence` proposals. | LOW | Expected behavior. Job runs weekly, produces audit trail. Once operators start reviewing ads, proposals will be generated. Min sample (30) prevents premature proposals. |
| O3 | **OpenAI embedding API downtime** ‚Äî `embed_descriptors()` calls OpenAI synchronously. Outage blocks visual embedding pipeline. | MEDIUM | Wrapped in try/except at pipeline node level. Review proceeds without exemplar context if embedding fails. Consider async retry queue in 8B. |

### Pre-existing Gaps (Not 8A-specific)

| # | Gap | Impact | Plan |
|---|-----|--------|------|
| E1 | **No eval baselines for ReviewAdsNode** ‚Äî No `tests/evals/` directory exists. Phase 8A modified the review prompt by adding optional `exemplar_context`, but the baseline gap predates Phase 8A. | Cannot automatically verify prompt changes don't degrade review quality. | Track as tech debt. Create eval baseline infrastructure in 8B or separate effort. |
| E2 | **No integration tests for worker handlers** ‚Äî Worker handlers (`execute_quality_calibration_job`, `execute_genome_validation_job`) are thin wiring, but not tested end-to-end. | Worker bugs only caught in production. | Existing pattern across all worker handlers. Consider integration test framework in future. |

### Phase 8B Implementation Risks

| # | Risk | Severity | Likelihood | Mitigation |
|---|------|----------|------------|------------|
| R10 | **Scorer weight learning cold start** ‚Äî All brands start in "cold" phase (static weights only). Requires 30+ matured ads with selection snapshots before any learning begins. Until then, the system behaves identically to pre-8B. | LOW | HIGH | Intended design. Cold phase uses proven static weights. Warm phase blends linearly. No brand experiences degraded selection during ramp-up. |
| R11 | **Credit assignment noise** ‚Äî Contribution-weighted update attributes reward to scorers based on `W_i * S_i / Œ£(W_j * S_j)`. With few non-zero scorers, attribution signal is noisy and may reinforce random correlations. | MEDIUM | MEDIUM | Soft updates (0.3√ó for low-contribution scorers) dampen noise. Safety rails: weight floor 0.1, ceiling 2.0, max ¬±0.15 delta per weekly update. Phase transition requires 100+ observations before full autonomy. |
| R12 | **Mann-Whitney U power with small samples** ‚Äî Binary approval data (1/0) with <50 ads per arm produces low statistical power. Normal approximation in tie-corrected variance degrades below n=20. | MEDIUM | MEDIUM | `min_sample_size` default = 20 ads (not runs). Service returns `inconclusive` rather than false positives when power is insufficient. Tie correction formula handles the extreme-tie case correctly (tested with heavy-tie binary data). |
| R13 | **Cross-brand transfer leakage** ‚Äî Transferred priors (element score posteriors, interaction effects) could leak strategic information about creative preferences between brands in the same org. | LOW | LOW | Only statistical aggregates cross boundaries (no ad content, images, or prompts). Org-scoped (no cross-org transfer). Opt-in per brand (`cross_brand_sharing` default FALSE). Shrinkage factor (0.3√ó) limits influence. Brand similarity gating planned. |
| R14 | **DBSCAN eps sensitivity** ‚Äî Cosine distance threshold (eps=0.3) hardcoded. Different brands/visual styles may produce vastly different cluster structures. Too-small eps = all noise; too-large = one mega-cluster. | LOW | MEDIUM | Default eps=0.3 works well for normalized embeddings. Noise points (cluster_label=-1) are expected and handled. Cluster quality visible in UI (Visual Clusters tab). Future: auto-tune eps via silhouette score. |
| R15 | **Whitespace false positives** ‚Äî Predicted potential from `mean(score_a, score_b) + synergy + novelty` may not reflect actual pair performance. Novelty bonus inflates untested combos. | LOW | HIGH | Candidates are advisory only (injected into prompts as suggestions, not constraints). Top 20 capped. Candidates tracked (`status`: identified ‚Üí injected ‚Üí tested ‚Üí dismissed). Novelty bonus decays with usage. |
| R16 | **Selection snapshot volume** ‚Äî Every pipeline run records a `selection_weight_snapshots` row. High-volume brands (100+ runs/day) could grow this table quickly. No TTL or archival policy. | LOW | LOW | Most brands run 1-10 pipeline runs/day. At 100 rows/day, 90 days = 9K rows per brand ‚Äî manageable. Monitor table size. Consider archiving snapshots > 90 days in future. |
| R17 | **Experiment arm contamination via timestamp** ‚Äî Seed uses `sha256(product_id:template_id:timestamp_minute)`. Two runs in the same minute for the same product+template get the same arm. | LOW | LOW | Intentional for replay stability (retries get consistent assignment). Different templates get different arms. Different minutes get different arms. True randomization not needed ‚Äî deterministic split ratio is sufficient. |

### Phase 8B Operational Risks

| # | Risk | Severity | Mitigation |
|---|------|----------|------------|
| O4 | **Migration table count** ‚Äî Phase 8B adds 7 new tables. Large migration may timeout on constrained Supabase plans. | LOW | Tables are small (no data migration, just DDL). Run in Supabase SQL editor with extended timeout if needed. |
| O5 | **Worker genome_validation job duration** ‚Äî Piggybacking weight learning + whitespace + clustering on weekly genome_validation extends job runtime. | MEDIUM | Each addition is individually wrapped in try/except (non-fatal). Clustering is the most expensive (O(n¬≤) distance matrix) but bounded by per-brand embedding count. Monitor job duration after deployment. |
| O6 | **sklearn dependency for DBSCAN** ‚Äî VisualClusteringService includes a pure Python DBSCAN fallback, but sklearn import is attempted first. If sklearn is not installed, fallback activates automatically. | LOW | Pure Python implementation is correct but slower. At >1000 embeddings per brand, consider ensuring sklearn is available. Current brand sizes are well within pure Python performance range. |

---

## Change Log

| Date | Phase | Change |
|------|-------|--------|
| 2026-02-16 | 1-3 | Initial plan created (Phase 8A scope) |
| 2026-02-16 | 4 | Implementation complete (P8A-C1 through P8A-C8) |
| 2026-02-16 | 4 | Post-plan review: fixed SQL injection in combo tracking, fixed weight preset test regression |
| 2026-02-16 | 4 | Added Risks & Mitigations section, expanded test coverage for CRUD methods |
| 2026-02-16 | 4 | Phase 8B implementation complete (C1-C13): 6 features, 10 new files, 9 modified, 63 new tests, 834 total passing |
| 2026-02-16 | 4 | Added Phase 8B risks (R10-R17, O4-O6) to risk register |
