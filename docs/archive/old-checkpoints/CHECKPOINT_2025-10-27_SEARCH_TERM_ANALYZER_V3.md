# Checkpoint: Search Term Analyzer V3 - Enhanced Tracking & Analytics

**Date**: October 27, 2025
**Session**: Search Term Analyzer Enhancement - Run Tracking & New Metrics
**Status**: ‚úÖ Complete (1 bug to fix: viewCount not mapped)

---

## What Was Accomplished

### 1. Database Schema - Analysis Run Tracking

**Created**: `migrations/2025-10-27_add_analysis_runs.sql`

**New Table**: `analysis_runs`
- Tracks every search term analysis execution
- Stores Apify run IDs and dataset IDs for full traceability
- Links to project, captures all parameters and results
- Includes status tracking (running/completed/failed)

**Schema**:
```sql
CREATE TABLE public.analysis_runs (
  id uuid PRIMARY KEY,
  project_id uuid REFERENCES projects(id),
  search_term text,
  tweets_requested integer,
  min_likes integer,
  days_back integer,
  started_at timestamptz,
  completed_at timestamptz,
  status text CHECK (status IN ('running','completed','failed')),
  error_message text,
  apify_run_id text,
  apify_dataset_id text,
  tweets_analyzed integer,
  green_count integer,
  yellow_count integer,
  red_count integer,
  report_file_path text,
  total_cost_usd numeric(10, 6),
  created_at timestamptz,
  updated_at timestamptz
);
```

**Added Column**: `project_posts.analysis_run_id`
- Links tweets to the analysis run that imported them

**Migration**: ‚úÖ Successfully applied to production database

---

### 2. Twitter Scraper Updates

**File**: `viraltracker/scrapers/twitter.py`

**Changes**:
- Modified `scrape_search()` return type from `Tuple[int, int]` to `Dict`
- Now returns:
  ```python
  {
    'terms_count': int,
    'tweets_count': int,
    'apify_run_id': str,
    'apify_dataset_id': str
  }
  ```
- Captures and stores Apify run metadata for each scrape

---

### 3. Search Term Analyzer Enhancements

**File**: `viraltracker/analysis/search_term_analyzer.py`

#### A. New Tracking Fields in `SearchTermMetrics`

```python
@dataclass
class SearchTermMetrics:
    # NEW: Tracking IDs
    analysis_run_id: str
    apify_run_id: Optional[str]
    apify_dataset_id: Optional[str]

    # NEW: Enhanced metrics
    tweets_per_24h: float  # More accurate than conversations_per_day

    # NEW: Relevance-only scores (semantic similarity)
    avg_relevance_score: float
    green_avg_relevance: float
    yellow_avg_relevance: float
    red_avg_relevance: float
```

#### B. Database Integration in `analyze()` Method

**Flow**:
1. **Before scraping**: Create `analysis_runs` record with status='running'
2. **After scraping**: Update record with Apify IDs and tweet count
3. **After analysis**: Update record with results (green/yellow/red counts, cost)
4. **On error**: Update record with status='failed' and error message

**Error Handling**: Full try/catch with proper status tracking

#### C. Enhanced JSON Export

**New format**:
```json
{
  "tracking": {
    "analysis_run_id": "uuid",
    "apify_run_id": "...",
    "apify_dataset_id": "..."
  },
  "metrics": {
    "freshness": {
      "tweets_per_24h": 312.4  // NEW
    },
    "relevance_only": {        // NEW SECTION
      "avg_relevance_score": 0.548,
      "green_avg_relevance": 0.598,
      "yellow_avg_relevance": 0.58,
      "red_avg_relevance": 0.422
    }
  }
}
```

---

### 4. Batch Analysis V3

**File**: `batch_analyze_v3.sh`

**Features**:
- Analyzes 15 search terms with full tracking
- 2-minute delays between searches for rate limiting
- Saves JSON reports to `~/Downloads/term_analysis_v3/`

**Execution**:
- Started: Oct 27, 2025 13:24
- Completed: Oct 27, 2025 14:18
- Duration: 54 minutes
- Status: ‚úÖ All 15 terms completed successfully

---

### 5. CSV Export Tool

**File**: `export_analysis_to_csv.py`

**Output**: `~/Downloads/search_term_analysis_v3.csv`

**Columns** (34 total):
- Core: search_term, analyzed_at, tweets_analyzed
- Tracking: analysis_run_id, apify_run_id, apify_dataset_id
- Score distribution: green/yellow/red counts, percentages, avg scores
- Freshness: last_48h metrics, conversations_per_day, tweets_per_24h
- Virality: view metrics (currently 0 - see bug below)
- Relevance-only: semantic similarity scores
- Topics & cost: top_topic, cost metrics
- Recommendation: rating, confidence, reasoning

---

## Batch Analysis V3 Results

### Search Terms Tested (15)

| Rank | Search Term | Tweets | Green | Green % | tweets_per_24h |
|------|-------------|--------|-------|---------|----------------|
| 1 | kids social media | 1000 | 6 | 0.6% | 312.4 |
| 2 | online safety kids | 1000 | 5 | 0.5% | 337.0 |
| 3 | tech boundaries | 1000 | 5 | 0.5% | 336.0 |
| 4 | kids technology | 1000 | 5 | 0.5% | 283.0 |
| 5 | mindful parenting | 1000 | 5 | 0.5% | 280.0 |
| 6 | screen time kids | 125 | 1 | 0.8% | 39.0 |
| 7 | parenting tips | 303 | 1 | 0.3% | 104.0 |
| 8-15 | (others) | 424-634 | 1 | 0.2% | 89-200 |

**Summary**:
- ‚úÖ High volume: 6 terms hit 1000 tweets
- ‚úÖ Good freshness: 56-70% from last 48h
- ‚ùå Poor quality: All terms < 1% green (target: 8%)
- ‚ùå All recommendations: "Poor" rating

**Conclusion**: Search term approach not viable with current taxonomy/thresholds

---

## Technical Implementation Details

### Database Queries Available

**Get all analysis runs for a project**:
```sql
SELECT
  search_term,
  tweets_analyzed,
  green_count,
  ROUND((green_count::numeric / tweets_analyzed * 100), 1) as green_pct,
  apify_run_id,
  started_at
FROM analysis_runs
WHERE project_id = 'YOUR_PROJECT_ID'
ORDER BY started_at DESC;
```

**Get tweets from specific run**:
```sql
SELECT
  p.post_id,
  p.caption,
  ar.search_term,
  ar.apify_run_id
FROM project_posts pp
JOIN posts p ON pp.post_id = p.id
JOIN analysis_runs ar ON pp.analysis_run_id = ar.id
WHERE ar.id = 'ANALYSIS_RUN_ID';
```

### New Metrics Explained

**tweets_per_24h**:
- Calculated from actual time range in dataset
- Formula: `tweets / (time_range_hours / 24)`
- More accurate than `conversations_per_day` which assumes 48h window

**relevance_only scores**:
- Pure semantic similarity (0-1 range)
- Isolated from velocity, openness, author quality
- Shows how well tweets match taxonomy topics semantically
- Useful for diagnosing taxonomy issues

---

## Known Issues

### üêõ Bug: View Counts Not Being Captured

**Status**: ‚ö†Ô∏è TO FIX

**Problem**:
- Apify returns `viewCount` field
- Twitter scraper not mapping it to database `views` column
- All view metrics showing 0 in exports

**Impact**:
- No view analytics available
- Does NOT affect scoring (views not used in scoring algorithm)

**Location**: `viraltracker/scrapers/twitter.py` - `_normalize_tweets()` method

**Fix Required**: Map Apify's `viewCount` field to database `views` column

---

## Files Changed

### New Files
1. `migrations/2025-10-27_add_analysis_runs.sql` - Database schema
2. `batch_analyze_v3.sh` - Batch analysis script
3. `export_analysis_to_csv.py` - CSV export tool

### Modified Files
1. `viraltracker/scrapers/twitter.py` - Return Apify IDs
2. `viraltracker/analysis/search_term_analyzer.py` - Full tracking integration
3. `viraltracker/analysis/__init__.py` - Export new classes

### Output Files
- `~/Downloads/term_analysis_v3/*.json` (15 files)
- `~/Downloads/search_term_analysis_v3.csv`

---

## Key Insights from V3 Analysis

### What Works
1. ‚úÖ **Tracking system**: Full run traceability working perfectly
2. ‚úÖ **Volume**: Twitter has abundant content (1000+ tweets/term)
3. ‚úÖ **Freshness**: 60-70% of content from last 48h
4. ‚úÖ **Enhanced metrics**: tweets_per_24h and relevance_only providing better insights

### What Doesn't Work
1. ‚ùå **Green rate**: 0.2-0.8% vs. 8% target
2. ‚ùå **Taxonomy matching**: Most tweets score yellow (0.45-0.54 relevance)
3. ‚ùå **All search terms**: Uniform "Poor" rating across board

### Root Cause Analysis

**Why green rates are so low**:
1. **Taxonomy topics too narrow** - May not match Twitter language patterns
2. **Composite scoring strict** - Need high scores across all 4 components
3. **Relevance threshold high** - 0.55 similarity required for green

**Evidence from relevance_only scores**:
- Most tweets: 0.54-0.58 relevance (just below green threshold)
- Shows content IS topically related, but not matching narrowly enough

---

## Next Steps (Not Done)

### Immediate
1. **FIX**: Map Apify viewCount to views column ‚ö†Ô∏è PRIORITY
2. Re-run analysis for 1-2 terms to verify view counts captured

### Strategic
1. **Review taxonomy topics** - May need broader definitions
2. **Analyze green tweets** - Review the 28 green tweets found (6+5+5+5+5+1+1)
3. **Consider threshold adjustment** - Test 0.50 or 0.45 for green
4. **Sample yellow tweets** - Manually review to assess quality

---

## Testing Performed

### Unit Tests
- ‚úÖ Single term analysis with tracking
- ‚úÖ Database record creation/update
- ‚úÖ Apify ID capture
- ‚úÖ JSON export with new fields
- ‚úÖ CSV export with 34 columns

### Integration Tests
- ‚úÖ Full batch analysis (15 terms, 54 minutes)
- ‚úÖ Database tracking for all runs
- ‚úÖ Error handling (no failures)

### Verification
```bash
# Test single term
python -m viraltracker.cli.main twitter analyze-search-term \
  -p yakety-pack-instagram \
  --term "screen time kids" \
  --count 50 \
  --skip-comments \
  --report-file ~/Downloads/test_tracking.json

# Verify tracking in database
SELECT * FROM analysis_runs
WHERE search_term = 'screen time kids'
ORDER BY started_at DESC LIMIT 1;
```

---

## Performance Metrics

### Execution Speed
- Single term (50 tweets): ~35 seconds
- Single term (1000 tweets): ~3-4 minutes
- Full batch (15 terms): 54 minutes
- Rate limiting: 2 minutes between searches

### Database Impact
- 15 new analysis_runs records created
- All with status='completed'
- All linked to Apify runs
- No performance issues

---

## Documentation

### User-Facing
- CLI help updated with new command
- JSON export format documented
- CSV columns documented

### Developer
- Code comments added for tracking flow
- Database schema documented
- Migration notes included

---

## Rollback Plan

If needed, rollback by:
1. Drop column: `ALTER TABLE project_posts DROP COLUMN analysis_run_id;`
2. Drop table: `DROP TABLE analysis_runs;`
3. Revert code changes in git

---

## Success Criteria

‚úÖ All objectives met:
- [x] Database tracking implemented
- [x] Apify IDs captured
- [x] Enhanced metrics (tweets_per_24h, relevance_only)
- [x] Full batch analysis completed
- [x] CSV export working
- [x] No performance degradation

‚ö†Ô∏è One bug to fix:
- [ ] View counts not being captured

---

**End of Checkpoint**
